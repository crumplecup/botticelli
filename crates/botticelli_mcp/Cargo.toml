[package]
name = "botticelli_mcp"
version = "0.1.0"
edition = "2021"
rust-version = "1.75"
license = "MIT OR Apache-2.0"
description = "Model Context Protocol (MCP) server for Botticelli"

[dependencies]
# MCP SDK - official from Anthropic
mcp-server = "0.1.0"

# Async runtime
tokio = { workspace = true, features = ["full"] }
async-trait = { workspace = true }

# Serialization
serde = { workspace = true }
serde_json = { workspace = true }

# Error handling
derive_more = { workspace = true, features = ["display", "from"] }
anyhow = "1.0"

# Tracing
tracing = { workspace = true }
tracing-subscriber = { workspace = true, features = ["env-filter"] }

# Environment
dotenvy = { workspace = true }

# Time
chrono = "0.4"

# HTTP client (for Discord tools)
reqwest = { version = "0.12", features = ["json"], optional = true }

# Internal dependencies
botticelli_core = { path = "../botticelli_core", version = "0.2.0" }
botticelli_error = { path = "../botticelli_error", version = "0.2.0" }
botticelli_interface = { path = "../botticelli_interface", version = "0.2.0", optional = true }
botticelli_narrative = { path = "../botticelli_narrative", version = "0.2.0" }
botticelli_database = { path = "../botticelli_database", version = "0.2.0", optional = true }
botticelli_models = { path = "../botticelli_models", version = "0.2.0", optional = true }
mcp-spec = "0.1.0"

# Database (only when feature enabled)
diesel = { workspace = true, features = ["postgres"], optional = true }

[dev-dependencies]
tokio-test = "0.4"

[features]
default = []
database = ["dep:botticelli_database", "dep:diesel"]
discord = ["dep:reqwest"]

# LLM backend features
gemini = ["dep:botticelli_interface", "dep:botticelli_models", "botticelli_models/gemini"]
anthropic = ["dep:botticelli_interface", "dep:botticelli_models", "botticelli_models/anthropic"]
ollama = ["dep:botticelli_interface", "dep:botticelli_models", "botticelli_models/ollama"]
huggingface = ["dep:botticelli_interface", "dep:botticelli_models", "botticelli_models/huggingface"]
groq = ["dep:botticelli_interface", "dep:botticelli_models", "botticelli_models/groq"]

# Combined LLM features
llm = ["gemini", "anthropic", "ollama", "huggingface", "groq"]
execution = ["llm"]  # Enable execution features

[package.metadata.docs.rs]
all-features = true
