[package]
name = "botticelli_models"
version.workspace = true
edition.workspace = true
license.workspace = true
authors.workspace = true
repository.workspace = true
keywords.workspace = true
categories.workspace = true
description = "LLM provider integrations for Botticelli"

[dependencies]
botticelli_error = { workspace = true }
botticelli_core = { workspace = true }
botticelli_interface = { workspace = true }
botticelli_rate_limit = { workspace = true, features = [] }

# Async runtime
tokio = { workspace = true }
async-trait = { workspace = true }
async-stream = { workspace = true }
futures-util = { workspace = true }
tokio-stream = { workspace = true }

# HTTP and serialization
reqwest = { workspace = true }
serde = { workspace = true }
serde_json = { workspace = true }

# Error handling
derive_more = { workspace = true, features = ["display", "error"] }
derive-getters = { workspace = true }
derive_builder = { workspace = true }

# Logging and metrics
tracing = { workspace = true }
opentelemetry = { workspace = true }

# Retry
tokio-retry2 = { workspace = true }

# Base64 encoding
base64 = { workspace = true }

# WebSocket
tokio-tungstenite = { workspace = true }

# Feature-gated provider SDKs
gemini-rust = { workspace = true, optional = true }
ollama-rs = { version = "0.3", optional = true, features = ["stream"] }
claude-client = { version = "0.3", optional = true }
futures = { workspace = true, optional = true }
hf-hub = { version = "0.4.3", optional = true }
huggingface_inference_rs = { version = "0.5.0", default-features = false, optional = true }
tiktoken-rs = "0.5"

[features]
default = []

# Generic model support (Driver trait, common types)
models = []

# Provider-specific features (each implies models)
gemini = ["dep:gemini-rust", "botticelli_rate_limit/gemini", "models"]
ollama = ["dep:ollama-rs", "botticelli_error/ollama", "models"]
anthropic = ["dep:claude-client", "dep:futures", "botticelli_rate_limit/anthropic", "botticelli_error/anthropic", "models"]

# OpenAI-compatible providers (use openai_compat module)
huggingface = ["botticelli_error/huggingface", "models"]
groq = ["botticelli_error/groq", "models"]
perplexity = []

# Combined features
local = ["gemini", "ollama", "anthropic", "huggingface", "groq", "perplexity"]

# Marker feature for tests that make real API calls
api = []

[dev-dependencies]
tokio = { workspace = true, features = ["macros", "rt-multi-thread"] }
dotenvy = { workspace = true }
anyhow = { workspace = true }
